#zad1
import numpy as np

def forwardPass(wiek, waga, wzrost):

    hidden1 = wiek * -0.46122 + waga * 0.97314 + wzrost * -0.39203 + 0.80109
    hidden1_po_aktywacji = 1/(1+np.exp(-hidden1))
    hidden2 = wiek * 0.78548 + waga * 2.10584 + wzrost * -0.57847 + 0.43529
    hidden2_po_aktywacji = 1/(1+np.exp(-hidden2))

    output = hidden1_po_aktywacji * -0.81546 + hidden2_po_aktywacji * 1.03775 + -0.2368

    return output


print(forwardPass(23,75,176))
print(forwardPass(25,67,180))

#zad2
import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler


# Załadowanie danych z pliku csv
iris_data = pd.read_csv("iris.csv")

# Podzielenie danych na cechy (features) i etykiety (labels)
X = iris_data.drop('variety', axis=1)
y = pd.get_dummies(iris_data['variety']) # zamiana etykiet na reprezentację one-hot

# Podzielenie danych na część testową i treningową
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Przeskalowanie danych (opcjonalnie)
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
from tensorflow.keras import layers

# Konstrukcja i wytrenowanie modelu sieci neuronowej
model = tf.keras.Sequential()
model.add(layers.Dense(4, input_shape=(4,), activation='relu'))
model.add(layers.Dense(2, activation='relu'))
model.add(layers.Dense(3, activation='softmax'))
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=100)

# Ewaluacja modelu na zbiorze testowym
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Dokładność modelu na zbiorze testowym:', test_acc)
